{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TxMM Code",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JellePiepenbrock/textmining2018/blob/master/TxMM_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "U6_2h652kSZV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## This is a streamlined version of the code used to train models for the Text Mining Project: Cross-Genre Text Author Gender PredictionUsing Logistic Regression and Bidirectional LSTM"
      ]
    },
    {
      "metadata": {
        "id": "q6CMBOzskeY0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### General imports"
      ]
    },
    {
      "metadata": {
        "id": "7CGoNGRSj5Uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import wordpunct_tokenize, sent_tokenize\n",
        "import nltk\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.svm import SVC\n",
        "import sklearn\n",
        "import spacy\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# stop_words = set(stopwords.words('dutch'))\n",
        "!spacy download nl_core_news_sm\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nl942aHWkDow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Read data and Create test sets"
      ]
    },
    {
      "metadata": {
        "id": "w_s1FOP2kBbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "newsloc = \"drive/My Drive/TextMining_Project/clin29/Training/GxG_News.txt\"\n",
        "twitterloc = \"drive/My Drive/TextMining_Project/clin29/Training/GxG_Twitter.txt\"\n",
        "youtubeloc = \"drive/My Drive/TextMining_Project/clin29/Training/GxG_YouTube.txt\"\n",
        "\n",
        "def parse_file(filelocation):\n",
        "\n",
        "  entries = []\n",
        "  identifiers = []\n",
        "  genders = []\n",
        "\n",
        "  for line in open(filelocation):\n",
        "    if line.startswith(\"<\"):\n",
        "      if line.startswith(\"<doc id\"):\n",
        "\n",
        "        identifier = line[9:12]\n",
        "        identifier = identifier.replace(\"\\\"\", \"\")\n",
        "        identifiers.append(int(identifier))\n",
        "\n",
        "        gender = re.search(r'gender', line)\n",
        "        gender = line[gender.end()+2:gender.end()+3]\n",
        "        genders.append(gender)\n",
        "\n",
        "        entry = []\n",
        "\n",
        "      if line.startswith(\"</doc>\"):\n",
        "        entries.append(''.join(entry))\n",
        "\n",
        "    else:\n",
        "      entry.append(line)\n",
        "\n",
        "  return entries, genders, identifiers\n",
        "\n",
        "  \n",
        "X_news, y_news, _ = parse_file(newsloc)\n",
        "X_tw, y_tw, _ = parse_file(twitterloc)\n",
        "X_yt, y_yt, _ = parse_file(youtubeloc)\n",
        "\n",
        "print(len(X_news), len(y_news))\n",
        "print(len(X_tw), len(y_tw))\n",
        "print(len(X_yt), len(y_yt))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-jeyjkenkPwF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for texts, genders, outputfolder in [(X_tw, y_tw, \"tw\"), (X_news, y_news, \"news\"), (X_yt, y_yt, \"yt\")]:\n",
        "  \n",
        "  length = len(texts)\n",
        "  print(length)\n",
        "  y_bin = np.array([0  if k==\"M\" else 1 for k in genders]).reshape((len(genders)))\n",
        "  print(len(y_bin))\n",
        "  p = np.random.permutation(len(y_bin))\n",
        "\n",
        "  x = pd.DataFrame(texts).iloc[p].values\n",
        "#   print(x)\n",
        "  y = y_bin[p]\n",
        "\n",
        "  training_x = x[:int(np.floor(0.8*length))]\n",
        "  training_y = y[:int(np.floor(0.8*length))]\n",
        "\n",
        "  val_x = x[int(np.floor(0.8*length)):int(np.floor(0.9*length))]\n",
        "  val_y = y[int(np.floor(0.8*length)):int(np.floor(0.9*length))]\n",
        "\n",
        "  test_x = x[int(np.floor(0.9*length)):]\n",
        "  test_y = y[int(np.floor(0.9*length)):]\n",
        "\n",
        "  training = pd.DataFrame()\n",
        "  val = pd.DataFrame()\n",
        "  test = pd.DataFrame()\n",
        "\n",
        "  training['label'] = training_y\n",
        "  training['text']  = training_x\n",
        "\n",
        "  val['label'] = val_y\n",
        "  val['text']  = val_x\n",
        "\n",
        "  test['label'] = test_y\n",
        "  test['text']  = test_x\n",
        "\n",
        "  # val = pd.DataFrame([training_x, training_y]).T\n",
        "  # test = pd.DataFrame([training_x, training_y]).T\n",
        "\n",
        "  # training.columns = ['label', 'text']\n",
        "  # val.columns = ['label', 'text']\n",
        "  # test.columns = ['label', 'text']\n",
        "  print(training)\n",
        "  print(val)\n",
        "  print(test)\n",
        "  \n",
        "  assert training.shape[0] + val.shape[0] + test.shape[0] == length\n",
        "#   print(len(training) + len(val) + len(test))\n",
        "\n",
        "#   training.to_csv(\"drive/My Drive/TextMining_Project/pl_data/{}/train.csv\".format(outputfolder), index=False, header=False)\n",
        "#   val.to_csv(\"drive/My Drive/TextMining_Project/pl_data/{}/val.csv\".format(outputfolder), index=False, header=False)\n",
        "#   test.to_csv(\"drive/My Drive/TextMining_Project/pl_data/{}/test.csv\".format(outputfolder), index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3O9T9vkbk6tE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "7S8sP7lXlQqd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = list(pd.read_table('/content/drive/My Drive/TextMining_Project/stopwords-nl.txt', header=None).iloc[:,0])\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "trainedclfs = []\n",
        "\n",
        "dataset_means = []\n",
        "\n",
        "for dataset in ['news', 'tw', 'yt']:\n",
        "  \n",
        "  train = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/train.csv'.format(dataset), header=None)\n",
        "  val = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/val.csv'.format(dataset), header=None)\n",
        "  test = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset), header=None)\n",
        "\n",
        "  \n",
        "  \n",
        "  train.columns = ['class', 'text']\n",
        "  val.columns = ['class', 'text']\n",
        "  test.columns = ['class', 'text']\n",
        "\n",
        "  trainval = pd.concat([train, val])\n",
        "  \n",
        "  kf = KFold(n_splits=5)\n",
        "  \n",
        "  accuracy_folds = []\n",
        "  \n",
        "  for e, (train_index, val_index) in enumerate(kf.split(trainval)): \n",
        "    print(\"Fold number: \", e+1)\n",
        "    accuracy_fold = []\n",
        "    train_fold, val_fold = trainval.iloc[train_index, :], trainval.iloc[val_index, :]\n",
        "  \n",
        "    vectorizer = CountVectorizer(min_df=100, analyzer='char', lowercase=False, ngram_range=(1, 3))\n",
        "    train_data = vectorizer.fit_transform(train_fold['text'])\n",
        "    val_data = vectorizer.transform(val_fold['text'])\n",
        "    test_data = vectorizer.transform(test['text'])\n",
        "    \n",
        "    print(train_data.shape)\n",
        "\n",
        "    wordvectorizer = TfidfVectorizer(min_df=100, analyzer='word', lowercase=False, ngram_range=(1,3))\n",
        "    train_data_word = wordvectorizer.fit_transform(train_fold['text'])\n",
        "    val_data_word = wordvectorizer.transform(val_fold['text'])\n",
        "    test_data_word = wordvectorizer.transform(test['text'])\n",
        "  \n",
        "    print(train_data_word.shape)\n",
        "    train_data = np.hstack([train_data.toarray(), train_data_word.toarray()])\n",
        "    val_data = np.hstack([val_data.toarray(), val_data_word.toarray()])\n",
        "    test_data = np.hstack([test_data.toarray(), test_data_word.toarray()])\n",
        "\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(train_data)\n",
        "\n",
        "    train_scaled = scaler.transform(train_data)\n",
        "    val_scaled = scaler.transform(val_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "    print(train_data.shape)\n",
        "\n",
        "    clf = LogisticRegression(C=1)\n",
        "    clf.fit(train_scaled, train_fold['class'])\n",
        "    trainedclfs.append(clf)\n",
        "\n",
        "    trainpreds = clf.predict(train_scaled)\n",
        "    valpreds = clf.predict(val_scaled)\n",
        "    testpreds = clf.predict(test_scaled)\n",
        "    train_acc = accuracy_score(train_fold['class'], trainpreds)\n",
        "    val_acc   = accuracy_score(val_fold['class'], valpreds)\n",
        "    test_acc  = accuracy_score(test['class'], testpreds)\n",
        "\n",
        "    print(\"Train acc: \", train_acc, \"Val acc: \", val_acc, \"Test acc: \", test_acc)\n",
        "    \n",
        "    accuracy_fold.append(train_acc)\n",
        "    accuracy_fold.append(val_acc)\n",
        "    accuracy_fold.append(test_acc)\n",
        "    \n",
        "    \n",
        "    for dataset_transfer in ['news', 'tw', 'yt']:\n",
        "      if dataset is not dataset_transfer:\n",
        "        test_transfer = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset_transfer), header=None)\n",
        "        test_transfer.columns = ['class', 'text']\n",
        "\n",
        "        test_transfer_data = vectorizer.transform(test_transfer['text'])\n",
        "        test_transfer_data_word = wordvectorizer.transform(test_transfer['text'])\n",
        "        test_transfer_data = np.hstack([test_transfer_data.toarray(), test_transfer_data_word.toarray()])\n",
        "\n",
        "        test_transfer_scaled = scaler.transform(test_transfer_data)\n",
        "        transferpreds = clf.predict(test_transfer_data)\n",
        "        transfer_acc = accuracy_score(test_transfer['class'], transferpreds)\n",
        "        print(dataset, \"->\", dataset_transfer, transfer_acc)\n",
        "        \n",
        "        accuracy_fold.append(transfer_acc)\n",
        "    accuracy_folds.append(accuracy_fold)\n",
        "  dataset_means.append(accuracy_folds)\n",
        "\n",
        "  \n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/TextMining_Project/logreg_kfold_results.pickle', 'wb') as handle:\n",
        "    pickle.dump(dataset_means, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SnHPao59lbM1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression with LSA inputs"
      ]
    },
    {
      "metadata": {
        "id": "av-AIkc7leor",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stopwords = list(pd.read_table('/content/drive/My Drive/TextMining_Project/stopwords-nl.txt', header=None).iloc[:,0])\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "trainedclfs = []\n",
        "\n",
        "dataset_means = []\n",
        "\n",
        "for dataset in ['news', 'tw', 'yt']:\n",
        "  \n",
        "  train = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/train.csv'.format(dataset), header=None)\n",
        "  val = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/val.csv'.format(dataset), header=None)\n",
        "  test = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset), header=None)\n",
        "\n",
        "  \n",
        "  \n",
        "  train.columns = ['class', 'text']\n",
        "  val.columns = ['class', 'text']\n",
        "  test.columns = ['class', 'text']\n",
        "\n",
        "  trainval = pd.concat([train, val])\n",
        "  \n",
        "  kf = KFold(n_splits=5)\n",
        "  \n",
        "  accuracy_folds = []\n",
        "  \n",
        "  for e, (train_index, val_index) in enumerate(kf.split(trainval)): \n",
        "    print(\"Fold number: \", e+1)\n",
        "    accuracy_fold = []\n",
        "    train_fold, val_fold = trainval.iloc[train_index, :], trainval.iloc[val_index, :]      \n",
        "    \n",
        "\n",
        "    \n",
        "    wordvectorizer = CountVectorizer(min_df=2, analyzer='word', lowercase=True, ngram_range=(1,3), stop_words=stopwords)\n",
        "    train_data_word = wordvectorizer.fit_transform(train_fold['text'])\n",
        "    val_data_word = wordvectorizer.transform(val_fold['text'])\n",
        "    test_data_word = wordvectorizer.transform(test['text'])\n",
        "    \n",
        "    print(train_data_word.shape)\n",
        "    # SVD represent documents and terms in vectors \n",
        "    svd_model_topics = TruncatedSVD(n_components=30, algorithm='randomized', n_iter=100, random_state=4711)\n",
        "\n",
        "    svd_model_topics.fit(train_data_word)\n",
        "    train_topics = svd_model_topics.transform(train_data_word)\n",
        "    val_topics = svd_model_topics.transform(val_data_word)\n",
        "    test_topics = svd_model_topics.transform(test_data_word)\n",
        "\n",
        "\n",
        "    train_data = np.hstack([train_topics])\n",
        "    val_data = np.hstack([val_topics])\n",
        "    test_data = np.hstack([test_topics])\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(train_data)\n",
        "\n",
        "    train_scaled = scaler.transform(train_data)\n",
        "    val_scaled = scaler.transform(val_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "    print(train_data.shape)\n",
        "\n",
        "    clf = LogisticRegression(C=1)\n",
        "    clf.fit(train_scaled, train_fold['class'])\n",
        "    trainedclfs.append(clf)\n",
        "\n",
        "    trainpreds = clf.predict(train_scaled)\n",
        "    valpreds = clf.predict(val_scaled)\n",
        "    testpreds = clf.predict(test_scaled)\n",
        "    train_acc = accuracy_score(train_fold['class'], trainpreds)\n",
        "    val_acc   = accuracy_score(val_fold['class'], valpreds)\n",
        "    test_acc  = accuracy_score(test['class'], testpreds)\n",
        "\n",
        "    print(\"Train acc: \", train_acc, \"Val acc: \", val_acc, \"Test acc: \", test_acc)\n",
        "    \n",
        "    accuracy_fold.append(train_acc)\n",
        "    accuracy_fold.append(val_acc)\n",
        "    accuracy_fold.append(test_acc)\n",
        "    \n",
        "    \n",
        "    for dataset_transfer in ['news', 'tw', 'yt']:\n",
        "      if dataset is not dataset_transfer:\n",
        "        test_transfer = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset_transfer), header=None)\n",
        "        test_transfer.columns = ['class', 'text']\n",
        "\n",
        "#         test_transfer_data = vectorizer.transform(test_transfer['text'])\n",
        "        test_transfer_data_word = wordvectorizer.transform(test_transfer['text'])\n",
        "#         test_transfer_lsa = svd_model_lsa.transform(test_transfer_data)\n",
        "        test_transfer_topics = svd_model_topics.transform(test_transfer_data_word)\n",
        "        test_transfer_data = np.hstack([test_transfer_topics])\n",
        "\n",
        "        test_transfer_scaled = scaler.transform(test_transfer_data)\n",
        "        transferpreds = clf.predict(test_transfer_data)\n",
        "        transfer_acc = accuracy_score(test_transfer['class'], transferpreds)\n",
        "        print(dataset, \"->\", dataset_transfer, transfer_acc)\n",
        "        \n",
        "        accuracy_fold.append(transfer_acc)\n",
        "    accuracy_folds.append(accuracy_fold)\n",
        "  dataset_means.append(accuracy_folds)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/TextMining_Project/logreg_lsa_kfold_results.pickle', 'wb') as handle:\n",
        "    pickle.dump(dataset_means, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v13qvF8Yjtw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# BidirectionalLSTM"
      ]
    },
    {
      "metadata": {
        "id": "gvXZ_TZgN-du",
        "colab_type": "code",
        "outputId": "9d11d759-7fd8-44b7-9a7e-0392c172d5fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, Bidirectional\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LoIplrgROJdY",
        "colab_type": "code",
        "outputId": "ac247daf-9af7-497d-abd0-7af392ce12e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OHAT8eXBY18J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## K-folding"
      ]
    },
    {
      "metadata": {
        "id": "1i9I7dNgO6lE",
        "colab_type": "code",
        "outputId": "8cbf388d-929d-4e02-981e-f06e195f2b59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11496
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "dataset_means = []\n",
        "for dataset in ['news', 'tw', 'yt']:\n",
        "  train = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/train.csv'.format(dataset), header=None)\n",
        "  val = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/val.csv'.format(dataset), header=None)\n",
        "  test = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset), header=None)\n",
        "  train.columns = ['class', 'text']\n",
        "  val.columns = ['class', 'text']\n",
        "  test.columns = ['class', 'text']\n",
        "\n",
        "  \n",
        "  trainval = pd.concat([train, val])\n",
        "  \n",
        "  kf = KFold(n_splits=5)\n",
        "  \n",
        "  accuracy_folds = []\n",
        "  \n",
        "  for e, (train_index, val_index) in enumerate(kf.split(trainval)): \n",
        "    print(\"Fold number: \", e+1)\n",
        "    accuracy_fold = []\n",
        "    train_fold, val_fold = trainval.iloc[train_index, :], trainval.iloc[val_index, :]\n",
        "    \n",
        "    def RNN():\n",
        "        inputs = Input(name='inputs',shape=[max_len])\n",
        "        layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "        layer = Bidirectional(LSTM(16))(layer)\n",
        "        layer = Dense(10,name='FC1')(layer)\n",
        "        layer = Activation('relu')(layer)\n",
        "        layer = Dropout(0.3)(layer)\n",
        "        layer = Dense(1,name='out_layer')(layer)\n",
        "        layer = Activation('sigmoid')(layer)\n",
        "        model = Model(inputs=inputs,outputs=layer)\n",
        "        return model\n",
        "    if dataset==\"news\":\n",
        "      max_len = 200\n",
        "    else:\n",
        "      max_len = 20\n",
        "\n",
        "    max_words = 3000\n",
        "\n",
        "    tok = Tokenizer(num_words=max_words)\n",
        "    tok.fit_on_texts(train['text'])\n",
        "    train_sequences = tok.texts_to_sequences(train_fold['text'])\n",
        "    val_sequences = tok.texts_to_sequences(val_fold['text'])\n",
        "    test_sequences = tok.texts_to_sequences(test['text'])\n",
        "\n",
        "    sequences_matrix = sequence.pad_sequences(train_sequences,maxlen=max_len)\n",
        "    val_sequences_matrix = sequence.pad_sequences(val_sequences,maxlen=max_len)\n",
        "    test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)\n",
        "\n",
        "    model = RNN()\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
        "\n",
        "    model.fit(sequences_matrix,train_fold['class'],batch_size=128,epochs=10,\n",
        "              validation_data=(val_sequences_matrix, val_fold['class']),callbacks=[EarlyStopping(patience=2, monitor='val_loss',min_delta=0.0001)])\n",
        "\n",
        "    train_acc = model.evaluate(sequences_matrix, train_fold['class'])[1]\n",
        "    val_acc = model.evaluate(val_sequences_matrix, val_fold['class'])[1]\n",
        "    test_acc = model.evaluate(test_sequences_matrix, test['class'])[1]\n",
        "    accuracy_fold.append(train_acc)\n",
        "    accuracy_fold.append(val_acc)\n",
        "    accuracy_fold.append(test_acc)\n",
        "    print(train_acc, val_acc, test_acc)\n",
        "\n",
        "\n",
        "    for dataset_transfer in ['news', 'tw', 'yt']:\n",
        "        if dataset is not dataset_transfer:\n",
        "          test_transfer = pd.read_csv('/content/drive/My Drive/TextMining_Project/pl_data/{}/test.csv'.format(dataset_transfer), header=None)\n",
        "          test_transfer.columns = ['class', 'text']\n",
        "\n",
        "          test_transfer_sequences = tok.texts_to_sequences(test_transfer['text'])\n",
        "          test_transfer_sequences_matrix = sequence.pad_sequences(test_transfer_sequences,maxlen=max_len)\n",
        "        \n",
        "          transfer_acc = model.evaluate(test_transfer_sequences_matrix, test_transfer['class'])[1]\n",
        "\n",
        "          print(dataset, \"->\", dataset_transfer, transfer_acc)\n",
        "          accuracy_fold.append(transfer_acc)\n",
        "          \n",
        "        \n",
        "    accuracy_folds.append(accuracy_fold)\n",
        "  dataset_means.append(accuracy_folds)\n",
        "\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/TextMining_Project/lstm_kfold_results.pickle', 'wb') as handle:\n",
        "    pickle.dump(dataset_means, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold number:  1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 200, 50)           150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1318 samples, validate on 330 samples\n",
            "Epoch 1/10\n",
            "1318/1318 [==============================] - 13s 10ms/step - loss: 0.6933 - acc: 0.5046 - val_loss: 0.6932 - val_acc: 0.4939\n",
            "Epoch 2/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.6904 - acc: 0.5432 - val_loss: 0.6925 - val_acc: 0.5061\n",
            "Epoch 3/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.6784 - acc: 0.6806 - val_loss: 0.6918 - val_acc: 0.5212\n",
            "Epoch 4/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.6406 - acc: 0.7291 - val_loss: 0.6889 - val_acc: 0.5242\n",
            "Epoch 5/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.5672 - acc: 0.7777 - val_loss: 0.6871 - val_acc: 0.5606\n",
            "Epoch 6/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.4994 - acc: 0.8141 - val_loss: 0.7449 - val_acc: 0.5576\n",
            "Epoch 7/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.4258 - acc: 0.8558 - val_loss: 0.7376 - val_acc: 0.5758\n",
            "1318/1318 [==============================] - 14s 10ms/step\n",
            "330/330 [==============================] - 4s 11ms/step\n",
            "184/184 [==============================] - 2s 10ms/step\n",
            "0.9226100152649539 0.5757575753963355 0.6304347800171893\n",
            "2000/2000 [==============================] - 20s 10ms/step\n",
            "news -> tw 0.5215\n",
            "1475/1475 [==============================] - 15s 10ms/step\n",
            "news -> yt 0.5240677966303745\n",
            "Fold number:  2\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 200, 50)           150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1318 samples, validate on 330 samples\n",
            "Epoch 1/10\n",
            "1318/1318 [==============================] - 13s 10ms/step - loss: 0.6940 - acc: 0.4985 - val_loss: 0.6933 - val_acc: 0.5152\n",
            "Epoch 2/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6894 - acc: 0.5797 - val_loss: 0.6935 - val_acc: 0.4667\n",
            "Epoch 3/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.6826 - acc: 0.6388 - val_loss: 0.6932 - val_acc: 0.5303\n",
            "Epoch 4/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6622 - acc: 0.7140 - val_loss: 0.6903 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "1318/1318 [==============================] - 11s 8ms/step - loss: 0.6044 - acc: 0.7337 - val_loss: 0.6686 - val_acc: 0.5667\n",
            "Epoch 6/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.5421 - acc: 0.7921 - val_loss: 0.6616 - val_acc: 0.5939\n",
            "Epoch 7/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.4960 - acc: 0.8065 - val_loss: 0.6687 - val_acc: 0.5909\n",
            "Epoch 8/10\n",
            "1318/1318 [==============================] - 11s 8ms/step - loss: 0.4378 - acc: 0.8376 - val_loss: 0.6696 - val_acc: 0.5788\n",
            "1318/1318 [==============================] - 13s 10ms/step\n",
            "330/330 [==============================] - 3s 10ms/step\n",
            "184/184 [==============================] - 2s 10ms/step\n",
            "0.9195751137183541 0.5787878787878787 0.5978260843650155\n",
            "2000/2000 [==============================] - 21s 11ms/step\n",
            "news -> tw 0.5015\n",
            "1475/1475 [==============================] - 15s 10ms/step\n",
            "news -> yt 0.5010169491727473\n",
            "Fold number:  3\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 200, 50)           150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1318 samples, validate on 330 samples\n",
            "Epoch 1/10\n",
            "1318/1318 [==============================] - 13s 10ms/step - loss: 0.6934 - acc: 0.4939 - val_loss: 0.6929 - val_acc: 0.5182\n",
            "Epoch 2/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6900 - acc: 0.5592 - val_loss: 0.6922 - val_acc: 0.5182\n",
            "Epoch 3/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6816 - acc: 0.6237 - val_loss: 0.6914 - val_acc: 0.5303\n",
            "Epoch 4/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6685 - acc: 0.6783 - val_loss: 0.6908 - val_acc: 0.5242\n",
            "Epoch 5/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.6441 - acc: 0.6730 - val_loss: 0.6849 - val_acc: 0.5273\n",
            "Epoch 6/10\n",
            "1318/1318 [==============================] - 12s 9ms/step - loss: 0.5927 - acc: 0.7785 - val_loss: 0.9366 - val_acc: 0.5182\n",
            "Epoch 7/10\n",
            "1318/1318 [==============================] - 11s 9ms/step - loss: 0.5466 - acc: 0.8209 - val_loss: 0.6772 - val_acc: 0.5697\n",
            "Epoch 8/10\n",
            "1318/1318 [==============================] - 11s 8ms/step - loss: 0.4896 - acc: 0.8520 - val_loss: 0.6801 - val_acc: 0.5545\n",
            "Epoch 9/10\n",
            "1318/1318 [==============================] - 11s 8ms/step - loss: 0.4217 - acc: 0.8801 - val_loss: 0.7061 - val_acc: 0.5697\n",
            "1318/1318 [==============================] - 13s 10ms/step\n",
            "330/330 [==============================] - 3s 10ms/step\n",
            "184/184 [==============================] - 2s 10ms/step\n",
            "0.9491654020339838 0.5696969704194502 0.5760869539302328\n",
            "2000/2000 [==============================] - 20s 10ms/step\n",
            "news -> tw 0.4915\n",
            "1475/1475 [==============================] - 15s 10ms/step\n",
            "news -> yt 0.5010169491727473\n",
            "Fold number:  4\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 200, 50)           150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1319 samples, validate on 329 samples\n",
            "Epoch 1/10\n",
            "1319/1319 [==============================] - 12s 9ms/step - loss: 0.6935 - acc: 0.4905 - val_loss: 0.6933 - val_acc: 0.4711\n",
            "Epoch 2/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.6927 - acc: 0.5216 - val_loss: 0.6936 - val_acc: 0.4681\n",
            "Epoch 3/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.6911 - acc: 0.5648 - val_loss: 0.6945 - val_acc: 0.4681\n",
            "1319/1319 [==============================] - 13s 10ms/step\n",
            "329/329 [==============================] - 3s 10ms/step\n",
            "184/184 [==============================] - 2s 10ms/step\n",
            "0.5208491282629371 0.46808510640562484 0.4836956534696662\n",
            "2000/2000 [==============================] - 19s 10ms/step\n",
            "news -> tw 0.508\n",
            "1475/1475 [==============================] - 14s 10ms/step\n",
            "news -> yt 0.5050847458031218\n",
            "Fold number:  5\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_6 (Embedding)      (None, 200, 50)           150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 1319 samples, validate on 329 samples\n",
            "Epoch 1/10\n",
            "1319/1319 [==============================] - 13s 10ms/step - loss: 0.6936 - acc: 0.4898 - val_loss: 0.6933 - val_acc: 0.4985\n",
            "Epoch 2/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.6894 - acc: 0.5413 - val_loss: 0.6928 - val_acc: 0.5167\n",
            "Epoch 3/10\n",
            "1319/1319 [==============================] - 12s 9ms/step - loss: 0.6825 - acc: 0.5800 - val_loss: 0.6906 - val_acc: 0.5319\n",
            "Epoch 4/10\n",
            "1319/1319 [==============================] - 12s 9ms/step - loss: 0.6598 - acc: 0.6907 - val_loss: 0.6849 - val_acc: 0.5350\n",
            "Epoch 5/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.6050 - acc: 0.7491 - val_loss: 0.6928 - val_acc: 0.5805\n",
            "Epoch 6/10\n",
            "1319/1319 [==============================] - 10s 8ms/step - loss: 0.5492 - acc: 0.7877 - val_loss: 0.6569 - val_acc: 0.6322\n",
            "Epoch 7/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.4802 - acc: 0.8324 - val_loss: 0.6709 - val_acc: 0.6170\n",
            "Epoch 8/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.4282 - acc: 0.8560 - val_loss: 0.6561 - val_acc: 0.6201\n",
            "Epoch 9/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.3754 - acc: 0.8840 - val_loss: 0.6925 - val_acc: 0.6231\n",
            "Epoch 10/10\n",
            "1319/1319 [==============================] - 11s 8ms/step - loss: 0.3286 - acc: 0.8961 - val_loss: 0.8088 - val_acc: 0.6079\n",
            "1319/1319 [==============================] - 14s 10ms/step\n",
            "329/329 [==============================] - 3s 10ms/step\n",
            "184/184 [==============================] - 2s 10ms/step\n",
            "0.8938589840788476 0.6079027358340637 0.5923913017563198\n",
            "2000/2000 [==============================] - 19s 10ms/step\n",
            "news -> tw 0.4945\n",
            "1475/1475 [==============================] - 14s 10ms/step\n",
            "news -> yt 0.4942372881557982\n",
            "Fold number:  1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_7 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/10\n",
            "14400/14400 [==============================] - 14s 998us/step - loss: 0.6901 - acc: 0.5347 - val_loss: 0.6810 - val_acc: 0.5933\n",
            "Epoch 2/10\n",
            "14400/14400 [==============================] - 12s 864us/step - loss: 0.6618 - acc: 0.6144 - val_loss: 0.6603 - val_acc: 0.5958\n",
            "Epoch 3/10\n",
            "14400/14400 [==============================] - 12s 850us/step - loss: 0.6311 - acc: 0.6546 - val_loss: 0.6550 - val_acc: 0.6147\n",
            "Epoch 4/10\n",
            "14400/14400 [==============================] - 12s 859us/step - loss: 0.6056 - acc: 0.6788 - val_loss: 0.6619 - val_acc: 0.5969\n",
            "Epoch 5/10\n",
            "14400/14400 [==============================] - 12s 849us/step - loss: 0.5912 - acc: 0.6952 - val_loss: 0.6674 - val_acc: 0.6028\n",
            "14400/14400 [==============================] - 16s 1ms/step\n",
            "3600/3600 [==============================] - 4s 1ms/step\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "0.7154861111111112 0.6027777777777777 0.6175\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "tw -> news 0.5489130434782609\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "tw -> yt 0.5444067796610169\n",
            "Fold number:  2\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/10\n",
            "14400/14400 [==============================] - 15s 1ms/step - loss: 0.6896 - acc: 0.5381 - val_loss: 0.6778 - val_acc: 0.5978\n",
            "Epoch 2/10\n",
            "14400/14400 [==============================] - 12s 847us/step - loss: 0.6589 - acc: 0.6127 - val_loss: 0.6529 - val_acc: 0.6164\n",
            "Epoch 3/10\n",
            "14400/14400 [==============================] - 12s 838us/step - loss: 0.6241 - acc: 0.6572 - val_loss: 0.6506 - val_acc: 0.6178\n",
            "Epoch 4/10\n",
            "14400/14400 [==============================] - 12s 866us/step - loss: 0.6028 - acc: 0.6813 - val_loss: 0.6698 - val_acc: 0.6186\n",
            "Epoch 5/10\n",
            "14400/14400 [==============================] - 12s 842us/step - loss: 0.5887 - acc: 0.6953 - val_loss: 0.6671 - val_acc: 0.5994\n",
            "14400/14400 [==============================] - 15s 1ms/step\n",
            "3600/3600 [==============================] - 4s 1ms/step\n",
            "2000/2000 [==============================] - 3s 1ms/step\n",
            "0.725625 0.5994444444444444 0.604\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "tw -> news 0.6141304321911024\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "tw -> yt 0.5254237288539693\n",
            "Fold number:  3\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_9 (Embedding)      (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/10\n",
            "14400/14400 [==============================] - 15s 1ms/step - loss: 0.6892 - acc: 0.5312 - val_loss: 0.6774 - val_acc: 0.5761\n",
            "Epoch 2/10\n",
            "14400/14400 [==============================] - 12s 844us/step - loss: 0.6556 - acc: 0.6126 - val_loss: 0.6624 - val_acc: 0.6011\n",
            "Epoch 3/10\n",
            "14400/14400 [==============================] - 12s 852us/step - loss: 0.6197 - acc: 0.6623 - val_loss: 0.6706 - val_acc: 0.6000\n",
            "Epoch 4/10\n",
            "14400/14400 [==============================] - 12s 841us/step - loss: 0.5956 - acc: 0.6880 - val_loss: 0.6727 - val_acc: 0.6097\n",
            "14400/14400 [==============================] - 15s 1ms/step\n",
            "3600/3600 [==============================] - 4s 1ms/step\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "0.7265972222222222 0.6097222222222223 0.625\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "tw -> news 0.5760869591132455\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "tw -> yt 0.5301694915658337\n",
            "Fold number:  4\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_10 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/10\n",
            "14400/14400 [==============================] - 15s 1ms/step - loss: 0.6883 - acc: 0.5375 - val_loss: 0.6728 - val_acc: 0.5917\n",
            "Epoch 2/10\n",
            "14400/14400 [==============================] - 12s 858us/step - loss: 0.6540 - acc: 0.6230 - val_loss: 0.6591 - val_acc: 0.5981\n",
            "Epoch 3/10\n",
            "14400/14400 [==============================] - 12s 858us/step - loss: 0.6232 - acc: 0.6631 - val_loss: 0.6572 - val_acc: 0.6050\n",
            "Epoch 4/10\n",
            "14400/14400 [==============================] - 12s 847us/step - loss: 0.5992 - acc: 0.6848 - val_loss: 0.6637 - val_acc: 0.5981\n",
            "Epoch 5/10\n",
            "14400/14400 [==============================] - 12s 844us/step - loss: 0.5795 - acc: 0.7001 - val_loss: 0.6789 - val_acc: 0.6025\n",
            "14400/14400 [==============================] - 15s 1ms/step\n",
            "3600/3600 [==============================] - 4s 1ms/step\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "0.7297222222222223 0.6025 0.6115\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "tw -> news 0.559782607399899\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "tw -> yt 0.535593220338983\n",
            "Fold number:  5\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_11 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/10\n",
            "14400/14400 [==============================] - 16s 1ms/step - loss: 0.6895 - acc: 0.5414 - val_loss: 0.6770 - val_acc: 0.5867\n",
            "Epoch 2/10\n",
            "14400/14400 [==============================] - 12s 849us/step - loss: 0.6512 - acc: 0.6184 - val_loss: 0.6677 - val_acc: 0.5994\n",
            "Epoch 3/10\n",
            "14400/14400 [==============================] - 12s 847us/step - loss: 0.6122 - acc: 0.6695 - val_loss: 0.6645 - val_acc: 0.6064\n",
            "Epoch 4/10\n",
            "14400/14400 [==============================] - 12s 837us/step - loss: 0.5856 - acc: 0.6960 - val_loss: 0.6814 - val_acc: 0.5950\n",
            "Epoch 5/10\n",
            "14400/14400 [==============================] - 12s 846us/step - loss: 0.5656 - acc: 0.7113 - val_loss: 0.6957 - val_acc: 0.5925\n",
            "14400/14400 [==============================] - 16s 1ms/step\n",
            "3600/3600 [==============================] - 4s 1ms/step\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "0.7543055555555556 0.5925 0.6205\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "tw -> news 0.5163043491218401\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "tw -> yt 0.5206779661421048\n",
            "Fold number:  1\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_12 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_12 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10615 samples, validate on 2654 samples\n",
            "Epoch 1/10\n",
            "10615/10615 [==============================] - 13s 1ms/step - loss: 0.6919 - acc: 0.5206 - val_loss: 0.6893 - val_acc: 0.5588\n",
            "Epoch 2/10\n",
            "10615/10615 [==============================] - 9s 840us/step - loss: 0.6734 - acc: 0.5931 - val_loss: 0.6757 - val_acc: 0.5833\n",
            "Epoch 3/10\n",
            "10615/10615 [==============================] - 9s 845us/step - loss: 0.6459 - acc: 0.6366 - val_loss: 0.6679 - val_acc: 0.5852\n",
            "Epoch 4/10\n",
            "10615/10615 [==============================] - 9s 831us/step - loss: 0.6185 - acc: 0.6635 - val_loss: 0.6805 - val_acc: 0.5976\n",
            "Epoch 5/10\n",
            "10615/10615 [==============================] - 11s 995us/step - loss: 0.5937 - acc: 0.6870 - val_loss: 0.6769 - val_acc: 0.5976\n",
            "10615/10615 [==============================] - 11s 1ms/step\n",
            "2654/2654 [==============================] - 3s 1ms/step\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "0.7252943946851406 0.5975885458610609 0.575593220359188\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "yt -> news 0.5489130421825077\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "yt -> tw 0.5235\n",
            "Fold number:  2\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_13 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_13 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10615 samples, validate on 2654 samples\n",
            "Epoch 1/10\n",
            "10615/10615 [==============================] - 13s 1ms/step - loss: 0.6923 - acc: 0.5197 - val_loss: 0.6898 - val_acc: 0.5644\n",
            "Epoch 2/10\n",
            "10615/10615 [==============================] - 9s 853us/step - loss: 0.6721 - acc: 0.5977 - val_loss: 0.6706 - val_acc: 0.5897\n",
            "Epoch 3/10\n",
            "10615/10615 [==============================] - 9s 855us/step - loss: 0.6321 - acc: 0.6405 - val_loss: 0.6742 - val_acc: 0.5810\n",
            "Epoch 4/10\n",
            "10615/10615 [==============================] - 9s 851us/step - loss: 0.6027 - acc: 0.6786 - val_loss: 0.6801 - val_acc: 0.5885\n",
            "10615/10615 [==============================] - 12s 1ms/step\n",
            "2654/2654 [==============================] - 3s 1ms/step\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "0.7217145548190252 0.5885455917844937 0.5810169491929523\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "yt -> news 0.5108695639216382\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "yt -> tw 0.5425\n",
            "Fold number:  3\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_14 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_14 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10615 samples, validate on 2654 samples\n",
            "Epoch 1/10\n",
            "10615/10615 [==============================] - 13s 1ms/step - loss: 0.6919 - acc: 0.5179 - val_loss: 0.6881 - val_acc: 0.5512\n",
            "Epoch 2/10\n",
            "10615/10615 [==============================] - 9s 856us/step - loss: 0.6690 - acc: 0.6010 - val_loss: 0.6725 - val_acc: 0.5833\n",
            "Epoch 3/10\n",
            "10615/10615 [==============================] - 9s 850us/step - loss: 0.6318 - acc: 0.6436 - val_loss: 0.6844 - val_acc: 0.5874\n",
            "Epoch 4/10\n",
            "10615/10615 [==============================] - 9s 851us/step - loss: 0.6047 - acc: 0.6744 - val_loss: 0.6951 - val_acc: 0.5957\n",
            "10615/10615 [==============================] - 12s 1ms/step\n",
            "2654/2654 [==============================] - 3s 1ms/step\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "0.6966556759134419 0.5957045970595503 0.5681355932607489\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "yt -> news 0.559782607399899\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "yt -> tw 0.5285\n",
            "Fold number:  4\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_15 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10615 samples, validate on 2654 samples\n",
            "Epoch 1/10\n",
            "10615/10615 [==============================] - 14s 1ms/step - loss: 0.6923 - acc: 0.5201 - val_loss: 0.6895 - val_acc: 0.5663\n",
            "Epoch 2/10\n",
            "10615/10615 [==============================] - 9s 848us/step - loss: 0.6750 - acc: 0.5982 - val_loss: 0.6700 - val_acc: 0.5852\n",
            "Epoch 3/10\n",
            "10615/10615 [==============================] - 9s 864us/step - loss: 0.6367 - acc: 0.6405 - val_loss: 0.6718 - val_acc: 0.5818\n",
            "Epoch 4/10\n",
            "10615/10615 [==============================] - 9s 859us/step - loss: 0.6045 - acc: 0.6755 - val_loss: 0.6737 - val_acc: 0.5916\n",
            "10615/10615 [==============================] - 11s 1ms/step\n",
            "2654/2654 [==============================] - 3s 1ms/step\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "0.7193593970852195 0.591559909480626 0.5688135593220339\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "yt -> news 0.6032608695652174\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "yt -> tw 0.5345\n",
            "Fold number:  5\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_16 (Embedding)     (None, 20, 50)            150000    \n",
            "_________________________________________________________________\n",
            "bidirectional_16 (Bidirectio (None, 32)                8576      \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 10)                330       \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "out_layer (Dense)            (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 158,917\n",
            "Trainable params: 158,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10616 samples, validate on 2653 samples\n",
            "Epoch 1/10\n",
            "10616/10616 [==============================] - 14s 1ms/step - loss: 0.6923 - acc: 0.5138 - val_loss: 0.6902 - val_acc: 0.5183\n",
            "Epoch 2/10\n",
            "10616/10616 [==============================] - 9s 834us/step - loss: 0.6779 - acc: 0.5862 - val_loss: 0.6782 - val_acc: 0.5530\n",
            "Epoch 3/10\n",
            "10616/10616 [==============================] - 9s 855us/step - loss: 0.6477 - acc: 0.6369 - val_loss: 0.6631 - val_acc: 0.5929\n",
            "Epoch 4/10\n",
            "10616/10616 [==============================] - 9s 857us/step - loss: 0.6161 - acc: 0.6716 - val_loss: 0.6647 - val_acc: 0.5967\n",
            "Epoch 5/10\n",
            "10616/10616 [==============================] - 9s 854us/step - loss: 0.5917 - acc: 0.6891 - val_loss: 0.6737 - val_acc: 0.5876\n",
            "10616/10616 [==============================] - 11s 1ms/step\n",
            "2653/2653 [==============================] - 3s 1ms/step\n",
            "1475/1475 [==============================] - 2s 1ms/step\n",
            "0.7322908816431013 0.5876366379033652 0.568135593220339\n",
            "184/184 [==============================] - 0s 1ms/step\n",
            "yt -> news 0.5326086943564208\n",
            "2000/2000 [==============================] - 2s 1ms/step\n",
            "yt -> tw 0.5335\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}